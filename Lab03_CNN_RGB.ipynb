{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab03_CNN_RGB.ipynb","version":"0.3.2","provenance":[{"file_id":"12zpjFGBYf5Dk0vnhttCk1EPc22ilydkl","timestamp":1567743375776},{"file_id":"1c1ghVbmJg2PW_la5iOZk2xpVmN8Zg6cW","timestamp":1567625588246},{"file_id":"1H5BsUvs93VFFLSE9U_vrByt-X0XDX7Wr","timestamp":1567612579915}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"TvEinm9YBQcS","colab_type":"code","colab":{}},"source":["import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FH4DaVHICJp6","colab_type":"code","colab":{}},"source":["np.random.seed(34)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FRxaGtESCSkT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2570cc4d-1c80-48fa-8efb-8f7ffc4dca60","executionInfo":{"status":"ok","timestamp":1567743505573,"user_tz":-330,"elapsed":3799,"user":{"displayName":"PHILEMON DANIEL","photoUrl":"","userId":"04120753151914153335"}}},"source":["import keras"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"v6NiTXT4CdV-","colab_type":"code","colab":{}},"source":["from keras.datasets import cifar10"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UJm4QV7iCloM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"24dd00d1-3097-471a-b21c-f45bf0989cc8","executionInfo":{"status":"ok","timestamp":1567743708245,"user_tz":-330,"elapsed":18623,"user":{"displayName":"PHILEMON DANIEL","photoUrl":"","userId":"04120753151914153335"}}},"source":["(X_train, y_train), (X_test, y_test) =cifar10.load_data()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 13s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xdJnqBJoCwPF","colab_type":"code","colab":{}},"source":["from keras.models import Sequential"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Djkv5VHvDjuc","colab_type":"code","colab":{}},"source":["from keras.layers import Dense, Convolution2D, Flatten, Activation, MaxPooling2D, Dropout"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QC6EXhUSEA3g","colab_type":"code","colab":{}},"source":["from keras.optimizers import SGD"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r8ToNRx9EIkP","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZRNez3CEEM9D","colab_type":"code","outputId":"66c622b5-09f1-4b92-d672-14eaadfc4e20","executionInfo":{"status":"ok","timestamp":1567743714348,"user_tz":-330,"elapsed":2209,"user":{"displayName":"PHILEMON DANIEL","photoUrl":"","userId":"04120753151914153335"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X_train.shape"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 32, 32, 3)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"O9hayquOEWJK","colab_type":"code","outputId":"e42d77cc-1355-454b-89ec-c9a9a265add1","executionInfo":{"status":"ok","timestamp":1567743718877,"user_tz":-330,"elapsed":1892,"user":{"displayName":"PHILEMON DANIEL","photoUrl":"","userId":"04120753151914153335"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["y_train.shape"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 1)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"IUFDsFw8FLkh","colab_type":"code","outputId":"86874fdd-5dde-4b36-9945-fa5164e9f20d","executionInfo":{"status":"ok","timestamp":1567743933616,"user_tz":-330,"elapsed":1907,"user":{"displayName":"PHILEMON DANIEL","photoUrl":"","userId":"04120753151914153335"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X_test.shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 32, 32, 3)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"e64ZIJR4FddI","colab_type":"code","outputId":"45f50620-7d2a-4614-b1a5-0fad18bdf6f3","executionInfo":{"status":"ok","timestamp":1567743936856,"user_tz":-330,"elapsed":2317,"user":{"displayName":"PHILEMON DANIEL","photoUrl":"","userId":"04120753151914153335"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["y_test.shape"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 1)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"ulN4xXHfGwW6","colab_type":"code","colab":{}},"source":["X_train =X_train.astype('float32') / 255"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9xwRTEfRG7qj","colab_type":"code","colab":{}},"source":["X_test =X_test.astype('float32') / 255"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9SVmOk68G_JK","colab_type":"code","colab":{}},"source":["X_train[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JGNfglV2HA3v","colab_type":"code","colab":{}},"source":["n_classes =10"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bp6XTDL7HWXD","colab_type":"code","colab":{}},"source":["y_train = keras.utils.to_categorical(y_train, n_classes)\n","y_test = keras.utils.to_categorical(y_test, n_classes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M0DVOVe5Ho3B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"835f2713-7a99-4296-9830-d1e0bbcd627b","executionInfo":{"status":"ok","timestamp":1567744107044,"user_tz":-330,"elapsed":2042,"user":{"displayName":"PHILEMON DANIEL","photoUrl":"","userId":"04120753151914153335"}}},"source":["model = Sequential()"],"execution_count":21,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0906 04:28:34.992483 139678805239680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"5aRLjvaXH4rh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"02ebd49b-fe35-4ed7-8c5d-09e10e17c41d","executionInfo":{"status":"ok","timestamp":1567744110273,"user_tz":-330,"elapsed":1910,"user":{"displayName":"PHILEMON DANIEL","photoUrl":"","userId":"04120753151914153335"}}},"source":["model.add(Convolution2D(32, (3, 3), padding='same', strides=(1,1), input_shape=X_train.shape[1:], activation='relu')) \n","# (Number_Input_Channels * Kernal_H * Kernal_W * Number_Output_Images) + Number_Output_Images = (1 * 3 * 3 * 32) + 32 = 320\n","model.add(Convolution2D(64, (3, 3), padding='valid', strides=(1,1), activation='relu'))\n","# (Number_Input_Channels * Kernal_H * Kernal_W * Number_Output_Images) + Number_Output_Images = (32 * 3 * 3 * 64) + 64 = 18496\n","#model.add(Convolution2D(16, (5, 5), padding='valid', strides=(1,1), activation='relu'))\n","# Output_Shape = (H-1), (W-1), "],"execution_count":22,"outputs":[{"output_type":"stream","text":["W0906 04:28:38.364172 139678805239680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0906 04:28:38.377266 139678805239680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"AZKLEI0riKpb","colab_type":"code","colab":{}},"source":["#model.add(MaxPooling2D(pool_size=(2, 2)))  # Only Forward Pass. Not used for Backprop.\n","# H/2, W/2 = 26/2, 26/2 = 13, 13\n","#model.add(Dropout(0.5))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gujB3jxpeYw5","colab_type":"code","colab":{}},"source":["model.add(Flatten())\n","# Number_Input_Channels * H * W = 64 * 13 * 13 = 10816"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IOm2RwNfIP9J","colab_type":"code","colab":{}},"source":["model.add(Dense(10, activation='softmax'))\n","# (Input_shape * Neurons) + Neurons = (10816 * 10) + 10"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RjRbC8UVIh0k","colab_type":"code","outputId":"83c0f671-ce96-431d-d4a7-d6a9dc7d8b18","executionInfo":{"status":"ok","timestamp":1567744122813,"user_tz":-330,"elapsed":1914,"user":{"displayName":"PHILEMON DANIEL","photoUrl":"","userId":"04120753151914153335"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["model.summary()"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 30, 30, 64)        18496     \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 57600)             0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                576010    \n","=================================================================\n","Total params: 595,402\n","Trainable params: 595,402\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ThnX5WXhJBvf","colab_type":"code","outputId":"39a7e140-bc2a-41fa-f358-7fe2e987687f","executionInfo":{"status":"ok","timestamp":1567744134341,"user_tz":-330,"elapsed":1916,"user":{"displayName":"PHILEMON DANIEL","photoUrl":"","userId":"04120753151914153335"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["model.compile(loss='mse', optimizer=SGD(lr=1),metrics=['accuracy'])"],"execution_count":26,"outputs":[{"output_type":"stream","text":["W0906 04:29:02.434227 139678805239680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"rGVlRcMuJUn2","colab_type":"code","outputId":"ceeaf0a6-1ca5-4abf-b353-52f615bd5e75","executionInfo":{"status":"error","timestamp":1567744722768,"user_tz":-330,"elapsed":587954,"user":{"displayName":"PHILEMON DANIEL","photoUrl":"","userId":"04120753151914153335"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.fit(X_train, y_train, batch_size=10000,epochs=200,verbose=1, \n","          validation_data=(X_test, y_test))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["W0906 04:29:04.973844 139678805239680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","W0906 04:29:04.997751 139678805239680 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 50000 samples, validate on 10000 samples\n","Epoch 1/200\n","50000/50000 [==============================] - 15s 299us/step - loss: 0.0898 - acc: 0.1199 - val_loss: 0.0894 - val_acc: 0.1314\n","Epoch 2/200\n","50000/50000 [==============================] - 4s 76us/step - loss: 0.0891 - acc: 0.1383 - val_loss: 0.0888 - val_acc: 0.1667\n","Epoch 3/200\n","50000/50000 [==============================] - 4s 76us/step - loss: 0.0885 - acc: 0.1787 - val_loss: 0.0880 - val_acc: 0.1973\n","Epoch 4/200\n","50000/50000 [==============================] - 4s 77us/step - loss: 0.0876 - acc: 0.2095 - val_loss: 0.0870 - val_acc: 0.2441\n","Epoch 5/200\n","50000/50000 [==============================] - 4s 77us/step - loss: 0.0866 - acc: 0.2359 - val_loss: 0.0859 - val_acc: 0.2425\n","Epoch 6/200\n","50000/50000 [==============================] - 4s 77us/step - loss: 0.0859 - acc: 0.2382 - val_loss: 0.0876 - val_acc: 0.1832\n","Epoch 7/200\n","50000/50000 [==============================] - 4s 77us/step - loss: 0.0897 - acc: 0.1853 - val_loss: 0.0948 - val_acc: 0.1009\n","Epoch 8/200\n","50000/50000 [==============================] - 4s 77us/step - loss: 0.0926 - acc: 0.1762 - val_loss: 0.0916 - val_acc: 0.2108\n","Epoch 9/200\n","50000/50000 [==============================] - 4s 77us/step - loss: 0.0915 - acc: 0.2091 - val_loss: 0.0910 - val_acc: 0.2077\n","Epoch 10/200\n","50000/50000 [==============================] - 4s 77us/step - loss: 0.0906 - acc: 0.2269 - val_loss: 0.0902 - val_acc: 0.2511\n","Epoch 11/200\n","50000/50000 [==============================] - 4s 77us/step - loss: 0.0894 - acc: 0.2432 - val_loss: 0.0885 - val_acc: 0.2500\n","Epoch 12/200\n","50000/50000 [==============================] - 4s 78us/step - loss: 0.0875 - acc: 0.2544 - val_loss: 0.0859 - val_acc: 0.2703\n","Epoch 13/200\n","50000/50000 [==============================] - 4s 78us/step - loss: 0.0854 - acc: 0.2807 - val_loss: 0.0856 - val_acc: 0.2821\n","Epoch 14/200\n","50000/50000 [==============================] - 4s 78us/step - loss: 0.0862 - acc: 0.2574 - val_loss: 0.0860 - val_acc: 0.2358\n","Epoch 15/200\n","50000/50000 [==============================] - 4s 78us/step - loss: 0.0874 - acc: 0.2382 - val_loss: 0.0885 - val_acc: 0.2535\n","Epoch 16/200\n","50000/50000 [==============================] - 4s 79us/step - loss: 0.0874 - acc: 0.2580 - val_loss: 0.0858 - val_acc: 0.2652\n","Epoch 17/200\n","50000/50000 [==============================] - 4s 79us/step - loss: 0.0845 - acc: 0.3018 - val_loss: 0.0861 - val_acc: 0.2757\n","Epoch 18/200\n","50000/50000 [==============================] - 4s 79us/step - loss: 0.0847 - acc: 0.2877 - val_loss: 0.0849 - val_acc: 0.2787\n","Epoch 19/200\n","50000/50000 [==============================] - 4s 79us/step - loss: 0.0873 - acc: 0.2410 - val_loss: 0.0844 - val_acc: 0.2966\n","Epoch 20/200\n","50000/50000 [==============================] - 4s 79us/step - loss: 0.0833 - acc: 0.3210 - val_loss: 0.0832 - val_acc: 0.3133\n","Epoch 21/200\n","50000/50000 [==============================] - 4s 80us/step - loss: 0.0844 - acc: 0.2861 - val_loss: 0.0850 - val_acc: 0.2850\n","Epoch 22/200\n","50000/50000 [==============================] - 4s 80us/step - loss: 0.0830 - acc: 0.3160 - val_loss: 0.0829 - val_acc: 0.3164\n","Epoch 23/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0830 - acc: 0.3006 - val_loss: 0.0799 - val_acc: 0.3508\n","Epoch 24/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0819 - acc: 0.3113 - val_loss: 0.0805 - val_acc: 0.3214\n","Epoch 25/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0820 - acc: 0.3009 - val_loss: 0.0840 - val_acc: 0.2647\n","Epoch 26/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0840 - acc: 0.2934 - val_loss: 0.0815 - val_acc: 0.3377\n","Epoch 27/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0842 - acc: 0.2924 - val_loss: 0.0851 - val_acc: 0.2697\n","Epoch 28/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0822 - acc: 0.3221 - val_loss: 0.0809 - val_acc: 0.3366\n","Epoch 29/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0808 - acc: 0.3339 - val_loss: 0.0782 - val_acc: 0.3617\n","Epoch 30/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0780 - acc: 0.3612 - val_loss: 0.0859 - val_acc: 0.2609\n","Epoch 31/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0831 - acc: 0.2890 - val_loss: 0.0813 - val_acc: 0.3217\n","Epoch 32/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0800 - acc: 0.3379 - val_loss: 0.0766 - val_acc: 0.3839\n","Epoch 33/200\n","50000/50000 [==============================] - 4s 83us/step - loss: 0.0797 - acc: 0.3371 - val_loss: 0.0772 - val_acc: 0.3723\n","Epoch 34/200\n","50000/50000 [==============================] - 4s 83us/step - loss: 0.0764 - acc: 0.3805 - val_loss: 0.0756 - val_acc: 0.3927\n","Epoch 35/200\n","50000/50000 [==============================] - 4s 83us/step - loss: 0.0836 - acc: 0.3041 - val_loss: 0.0856 - val_acc: 0.2384\n","Epoch 36/200\n","50000/50000 [==============================] - 4s 83us/step - loss: 0.0812 - acc: 0.3200 - val_loss: 0.0821 - val_acc: 0.3159\n","Epoch 37/200\n","50000/50000 [==============================] - 4s 83us/step - loss: 0.0796 - acc: 0.3450 - val_loss: 0.0803 - val_acc: 0.3261\n","Epoch 38/200\n","50000/50000 [==============================] - 4s 83us/step - loss: 0.0793 - acc: 0.3479 - val_loss: 0.0777 - val_acc: 0.3545\n","Epoch 39/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0797 - acc: 0.3340 - val_loss: 0.0763 - val_acc: 0.3832\n","Epoch 40/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0783 - acc: 0.3567 - val_loss: 0.0766 - val_acc: 0.3727\n","Epoch 41/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0774 - acc: 0.3658 - val_loss: 0.0763 - val_acc: 0.3728\n","Epoch 42/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0769 - acc: 0.3711 - val_loss: 0.0751 - val_acc: 0.3906\n","Epoch 43/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0773 - acc: 0.3640 - val_loss: 0.0760 - val_acc: 0.3839\n","Epoch 44/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0764 - acc: 0.3774 - val_loss: 0.0758 - val_acc: 0.3807\n","Epoch 45/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0771 - acc: 0.3650 - val_loss: 0.0787 - val_acc: 0.3400\n","Epoch 46/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0762 - acc: 0.3757 - val_loss: 0.0775 - val_acc: 0.3496\n","Epoch 47/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0762 - acc: 0.3770 - val_loss: 0.0747 - val_acc: 0.3951\n","Epoch 48/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0750 - acc: 0.3916 - val_loss: 0.0761 - val_acc: 0.3727\n","Epoch 49/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0766 - acc: 0.3712 - val_loss: 0.0765 - val_acc: 0.3675\n","Epoch 50/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0760 - acc: 0.3792 - val_loss: 0.0740 - val_acc: 0.4038\n","Epoch 51/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0759 - acc: 0.3789 - val_loss: 0.0748 - val_acc: 0.3960\n","Epoch 52/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0753 - acc: 0.3889 - val_loss: 0.0744 - val_acc: 0.3912\n","Epoch 53/200\n","50000/50000 [==============================] - 4s 83us/step - loss: 0.0750 - acc: 0.3923 - val_loss: 0.0737 - val_acc: 0.4036\n","Epoch 54/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0742 - acc: 0.4012 - val_loss: 0.0732 - val_acc: 0.4047\n","Epoch 55/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0757 - acc: 0.3786 - val_loss: 0.0733 - val_acc: 0.4078\n","Epoch 56/200\n","50000/50000 [==============================] - 4s 83us/step - loss: 0.0732 - acc: 0.4146 - val_loss: 0.0760 - val_acc: 0.3804\n","Epoch 57/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0741 - acc: 0.4006 - val_loss: 0.0766 - val_acc: 0.3594\n","Epoch 58/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0756 - acc: 0.3845 - val_loss: 0.0729 - val_acc: 0.4150\n","Epoch 59/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0738 - acc: 0.4013 - val_loss: 0.0748 - val_acc: 0.3862\n","Epoch 60/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0744 - acc: 0.3991 - val_loss: 0.0723 - val_acc: 0.4150\n","Epoch 61/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0738 - acc: 0.4008 - val_loss: 0.0750 - val_acc: 0.3868\n","Epoch 62/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0732 - acc: 0.4109 - val_loss: 0.0736 - val_acc: 0.3979\n","Epoch 63/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0727 - acc: 0.4154 - val_loss: 0.0720 - val_acc: 0.4232\n","Epoch 64/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0717 - acc: 0.4307 - val_loss: 0.0726 - val_acc: 0.4086\n","Epoch 65/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0730 - acc: 0.4107 - val_loss: 0.0726 - val_acc: 0.4145\n","Epoch 66/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0738 - acc: 0.4016 - val_loss: 0.0715 - val_acc: 0.4243\n","Epoch 67/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0735 - acc: 0.4055 - val_loss: 0.0716 - val_acc: 0.4275\n","Epoch 68/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0713 - acc: 0.4334 - val_loss: 0.0751 - val_acc: 0.3801\n","Epoch 69/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0741 - acc: 0.3979 - val_loss: 0.0712 - val_acc: 0.4314\n","Epoch 70/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0724 - acc: 0.4197 - val_loss: 0.0733 - val_acc: 0.4039\n","Epoch 71/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0714 - acc: 0.4301 - val_loss: 0.0715 - val_acc: 0.4194\n","Epoch 72/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0718 - acc: 0.4244 - val_loss: 0.0719 - val_acc: 0.4164\n","Epoch 73/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0721 - acc: 0.4210 - val_loss: 0.0754 - val_acc: 0.3827\n","Epoch 74/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0724 - acc: 0.4191 - val_loss: 0.0699 - val_acc: 0.4462\n","Epoch 75/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0709 - acc: 0.4357 - val_loss: 0.0753 - val_acc: 0.3852\n","Epoch 76/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0721 - acc: 0.4213 - val_loss: 0.0704 - val_acc: 0.4354\n","Epoch 77/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0712 - acc: 0.4315 - val_loss: 0.0714 - val_acc: 0.4240\n","Epoch 78/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0719 - acc: 0.4201 - val_loss: 0.0716 - val_acc: 0.4249\n","Epoch 79/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0721 - acc: 0.4192 - val_loss: 0.0698 - val_acc: 0.4420\n","Epoch 80/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0701 - acc: 0.4430 - val_loss: 0.0734 - val_acc: 0.4032\n","Epoch 81/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0724 - acc: 0.4168 - val_loss: 0.0711 - val_acc: 0.4310\n","Epoch 82/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0714 - acc: 0.4282 - val_loss: 0.0709 - val_acc: 0.4380\n","Epoch 83/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0711 - acc: 0.4346 - val_loss: 0.0704 - val_acc: 0.4381\n","Epoch 84/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0702 - acc: 0.4410 - val_loss: 0.0703 - val_acc: 0.4410\n","Epoch 85/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0714 - acc: 0.4281 - val_loss: 0.0725 - val_acc: 0.4050\n","Epoch 86/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0702 - acc: 0.4413 - val_loss: 0.0692 - val_acc: 0.4514\n","Epoch 87/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0700 - acc: 0.4439 - val_loss: 0.0721 - val_acc: 0.4116\n","Epoch 88/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0704 - acc: 0.4384 - val_loss: 0.0709 - val_acc: 0.4301\n","Epoch 89/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0701 - acc: 0.4445 - val_loss: 0.0702 - val_acc: 0.4352\n","Epoch 90/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0706 - acc: 0.4365 - val_loss: 0.0713 - val_acc: 0.4261\n","Epoch 91/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0703 - acc: 0.4412 - val_loss: 0.0711 - val_acc: 0.4242\n","Epoch 92/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0705 - acc: 0.4371 - val_loss: 0.0704 - val_acc: 0.4319\n","Epoch 93/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0691 - acc: 0.4555 - val_loss: 0.0697 - val_acc: 0.4397\n","Epoch 94/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0704 - acc: 0.4385 - val_loss: 0.0691 - val_acc: 0.4553\n","Epoch 95/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0682 - acc: 0.4664 - val_loss: 0.0700 - val_acc: 0.4394\n","Epoch 96/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0700 - acc: 0.4423 - val_loss: 0.0710 - val_acc: 0.4354\n","Epoch 97/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0697 - acc: 0.4477 - val_loss: 0.0719 - val_acc: 0.4111\n","Epoch 98/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0699 - acc: 0.4411 - val_loss: 0.0705 - val_acc: 0.4338\n","Epoch 99/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0696 - acc: 0.4462 - val_loss: 0.0687 - val_acc: 0.4564\n","Epoch 100/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0687 - acc: 0.4583 - val_loss: 0.0690 - val_acc: 0.4531\n","Epoch 101/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0692 - acc: 0.4517 - val_loss: 0.0698 - val_acc: 0.4406\n","Epoch 102/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0692 - acc: 0.4495 - val_loss: 0.0683 - val_acc: 0.4623\n","Epoch 103/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0682 - acc: 0.4630 - val_loss: 0.0711 - val_acc: 0.4216\n","Epoch 104/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0686 - acc: 0.4575 - val_loss: 0.0687 - val_acc: 0.4584\n","Epoch 105/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0689 - acc: 0.4533 - val_loss: 0.0695 - val_acc: 0.4419\n","Epoch 106/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0682 - acc: 0.4604 - val_loss: 0.0680 - val_acc: 0.4663\n","Epoch 107/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0683 - acc: 0.4610 - val_loss: 0.0709 - val_acc: 0.4307\n","Epoch 108/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0689 - acc: 0.4548 - val_loss: 0.0677 - val_acc: 0.4650\n","Epoch 109/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0674 - acc: 0.4712 - val_loss: 0.0688 - val_acc: 0.4591\n","Epoch 110/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0696 - acc: 0.4478 - val_loss: 0.0683 - val_acc: 0.4651\n","Epoch 111/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0682 - acc: 0.4646 - val_loss: 0.0676 - val_acc: 0.4691\n","Epoch 112/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0674 - acc: 0.4723 - val_loss: 0.0682 - val_acc: 0.4577\n","Epoch 113/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0683 - acc: 0.4593 - val_loss: 0.0684 - val_acc: 0.4551\n","Epoch 114/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0681 - acc: 0.4622 - val_loss: 0.0679 - val_acc: 0.4671\n","Epoch 115/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0671 - acc: 0.4754 - val_loss: 0.0681 - val_acc: 0.4607\n","Epoch 116/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0678 - acc: 0.4662 - val_loss: 0.0677 - val_acc: 0.4683\n","Epoch 117/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0670 - acc: 0.4734 - val_loss: 0.0685 - val_acc: 0.4549\n","Epoch 118/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0673 - acc: 0.4703 - val_loss: 0.0685 - val_acc: 0.4593\n","Epoch 119/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0673 - acc: 0.4725 - val_loss: 0.0672 - val_acc: 0.4689\n","Epoch 120/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0671 - acc: 0.4745 - val_loss: 0.0688 - val_acc: 0.4514\n","Epoch 121/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0668 - acc: 0.4767 - val_loss: 0.0674 - val_acc: 0.4685\n","Epoch 122/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0670 - acc: 0.4747 - val_loss: 0.0670 - val_acc: 0.4738\n","Epoch 123/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0674 - acc: 0.4693 - val_loss: 0.0676 - val_acc: 0.4634\n","Epoch 124/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0664 - acc: 0.4810 - val_loss: 0.0662 - val_acc: 0.4831\n","Epoch 125/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0663 - acc: 0.4811 - val_loss: 0.0667 - val_acc: 0.4747\n","Epoch 126/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0661 - acc: 0.4838 - val_loss: 0.0669 - val_acc: 0.4729\n","Epoch 127/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0660 - acc: 0.4838 - val_loss: 0.0669 - val_acc: 0.4755\n","Epoch 128/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0665 - acc: 0.4807 - val_loss: 0.0668 - val_acc: 0.4744\n","Epoch 129/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0663 - acc: 0.4786 - val_loss: 0.0673 - val_acc: 0.4688\n","Epoch 130/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0659 - acc: 0.4862 - val_loss: 0.0659 - val_acc: 0.4820\n","Epoch 131/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0657 - acc: 0.4859 - val_loss: 0.0654 - val_acc: 0.4862\n","Epoch 132/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0655 - acc: 0.4904 - val_loss: 0.0661 - val_acc: 0.4797\n","Epoch 133/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0652 - acc: 0.4947 - val_loss: 0.0678 - val_acc: 0.4611\n","Epoch 134/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0667 - acc: 0.4777 - val_loss: 0.0659 - val_acc: 0.4832\n","Epoch 135/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0650 - acc: 0.4956 - val_loss: 0.0674 - val_acc: 0.4694\n","Epoch 136/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0657 - acc: 0.4877 - val_loss: 0.0652 - val_acc: 0.4944\n","Epoch 137/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0645 - acc: 0.5020 - val_loss: 0.0669 - val_acc: 0.4740\n","Epoch 138/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0652 - acc: 0.4900 - val_loss: 0.0646 - val_acc: 0.4994\n","Epoch 139/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0653 - acc: 0.4919 - val_loss: 0.0661 - val_acc: 0.4800\n","Epoch 140/200\n","50000/50000 [==============================] - 4s 82us/step - loss: 0.0653 - acc: 0.4909 - val_loss: 0.0658 - val_acc: 0.4815\n","Epoch 141/200\n","50000/50000 [==============================] - 4s 81us/step - loss: 0.0643 - acc: 0.5027 - val_loss: 0.0651 - val_acc: 0.4973\n","Epoch 142/200\n","20000/50000 [===========>..................] - ETA: 2s - loss: 0.0640 - acc: 0.5046"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-6b26c283ee9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(X_train, y_train, batch_size=10000,epochs=200,verbose=1, \n\u001b[0;32m----> 2\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"d4hlU8xwkyzw","colab_type":"code","outputId":"941f081f-63ae-466e-81de-a59ea8a23f54","executionInfo":{"status":"ok","timestamp":1567622553980,"user_tz":-330,"elapsed":1459,"user":{"displayName":"Philemon Daniel","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBKTwt_K_gkJLv7YplBQKVxH8P8dqn-XwgiCwzUjw=s64","userId":"06587091607560878110"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["score = model.evaluate(X_test, y_test, verbose=1) \n","print('loss=', score[0]) \n","print('accuracy=', score[1]) \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["10000/10000 [==============================] - 1s 66us/step\n","loss= 0.011759458650136367\n","accuracy= 0.9236\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1JCw82KNlUmc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}