{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMiOm3UunnnxwXaxN50bQAq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","\n","# Number of bits\n","N = 4\n","\n","# Generate all possible combinations of inputs\n","inputs = np.array(np.meshgrid(*[range(2)]*(N*2+1))).T.reshape(-1, N*2+1)\n","\n","# Initialize the outputs\n","outputs = np.zeros((2**9, N+1), dtype=int)\n","\n","# Compute the outputs for each input\n","for i, x in enumerate(inputs):\n","    # Extract A, B, and CIN from x\n","    A = x[:N][::-1]\n","    B = x[N:-1][::-1]\n","    CIN = x[-1]\n","    \n","    # Perform the addition\n","    CARRY = CIN\n","    for j in range(N):\n","        outputs[i, j] = A[j] ^ B[j] ^ CARRY\n","        CARRY = (A[j] & B[j]) | (A[j] & CARRY) | (B[j] & CARRY)\n","    \n","    # The final carry out is the last bit of the sum\n","    outputs[i, -1] = CARRY\n","\n","# Reverse the bits to match the input order\n","outputs = outputs[:, ::-1]\n","\n","print('Inputs:', inputs)\n","print('Outputs:', outputs)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DCt8DglOOTr-","executionInfo":{"status":"ok","timestamp":1685996525958,"user_tz":-330,"elapsed":445,"user":{"displayName":"Philemon Daniel","userId":"06587091607560878110"}},"outputId":"57f25b2f-533c-4b3f-a6a6-6d7f1ad960ea"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Inputs: [[0 0 0 ... 0 0 0]\n"," [0 1 0 ... 0 0 0]\n"," [1 0 0 ... 0 0 0]\n"," ...\n"," [0 1 1 ... 1 1 1]\n"," [1 0 1 ... 1 1 1]\n"," [1 1 1 ... 1 1 1]]\n","Outputs: [[0 0 0 0 0]\n"," [0 0 1 0 0]\n"," [0 1 0 0 0]\n"," ...\n"," [1 0 1 1 1]\n"," [1 1 0 1 1]\n"," [1 1 1 1 1]]\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","# Step 3: Create a dataset for a 4-bit full adder\n","\n","# Number of bits\n","N = 4\n","\n","# Generate all possible combinations of inputs\n","inputs = np.array(np.meshgrid(*[range(2)]*(N*2+1))).T.reshape(-1, N*2+1)\n","\n","# Initialize the outputs\n","outputs = np.zeros((2**9, N+1), dtype=int)\n","\n","# Compute the outputs for each input\n","for i, x in enumerate(inputs):\n","    # Extract A, B, and CIN from x\n","    A = x[:N][::-1]\n","    B = x[N:-1][::-1]\n","    CIN = x[-1]\n","    \n","    # Perform the addition\n","    CARRY = CIN\n","    for j in range(N):\n","        outputs[i, j] = A[j] ^ B[j] ^ CARRY\n","        CARRY = (A[j] & B[j]) | (A[j] & CARRY) | (B[j] & CARRY)\n","    \n","    # The final carry out is the last bit of the sum\n","    outputs[i, -1] = CARRY\n","\n","# Reverse the bits to match the input order\n","outputs = outputs[:, ::-1]\n","\n","# Combine inputs and outputs\n","input_data = np.concatenate([inputs, outputs], axis=1)\n","\n","# Step 4 and 5: Build and train a Binary Variational Autoencoder (VAE)\n","\n","# Define the parameters\n","original_dim = 2*N+1 + N+1 # input dimension\n","intermediate_dim = 50 # size of the hidden layers\n","latent_dim = 20 # size of the latent space\n","\n","# Define the Encoder\n","inputs_layer = tf.keras.Input(shape=(original_dim,))\n","h = layers.Dense(intermediate_dim, activation='relu')(inputs_layer)\n","z_mean = layers.Dense(latent_dim)(h)\n","z_log_var = layers.Dense(latent_dim)(h)\n","\n","# Define the sampling function\n","def sampling(args):\n","    z_mean, z_log_var = args\n","    epsilon = tf.keras.backend.random_normal(shape=(tf.shape(z_mean)[0], latent_dim))\n","    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n","\n","# Use the sampling function to create a layer\n","z = layers.Lambda(sampling)([z_mean, z_log_var])\n","\n","# Create the Encoder model\n","encoder = tf.keras.Model(inputs_layer, [z_mean, z_log_var, z], name='encoder')\n","\n","# Define the Decoder\n","latent_inputs = tf.keras.Input(shape=(latent_dim,))\n","x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n","outputs_layer = layers.Dense(original_dim, activation='sigmoid')(x)\n","\n","# Create the Decoder model\n","decoder = tf.keras.Model(latent_inputs, outputs_layer, name='decoder')\n","\n","# Define the VAE as a model with a custom train_step\n","class VAE(tf.keras.Model):\n","    def __init__(self, encoder, decoder, **kwargs):\n","        super(VAE, self).__init__(**kwargs)\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n","        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(\n","            name=\"reconstruction_loss\"\n","        )\n","        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n","\n","    @property\n","    def metrics(self):\n","        return [\n","            self.total_loss_tracker,\n","            self.reconstruction_loss_tracker,\n","            self.kl_loss_tracker,\n","        ]\n","\n","    def train_step(self, data):\n","        with tf.GradientTape() as tape:\n","            z_mean, z_log_var, z = self.encoder(data)\n","            reconstruction = self.decoder(z)\n","            reconstruction_loss = tf.reduce_mean(\n","                tf.keras.losses.binary_crossentropy(data, reconstruction)\n","            )\n","            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n","            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n","            total_loss = reconstruction_loss + kl_loss\n","        grads = tape.gradient(total_loss, self.trainable_weights)\n","        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n","        self.total_loss_tracker.update_state(total_loss)\n","        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n","        self.kl_loss_tracker.update_state(kl_loss)\n","        return {\n","            \"loss\": self.total_loss_tracker.result(),\n","            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n","            \"kl_loss\": self.kl_loss_tracker.result(),\n","        }\n","\n","# Instantiate the VAE model\n","vae = VAE(encoder, decoder)\n","\n","# Compile and train the VAE\n","\n","vae.compile(optimizer=tf.keras.optimizers.Adam())\n","vae.fit(input_data, epochs=300, batch_size=32)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sm3uIeqIOVLt","executionInfo":{"status":"ok","timestamp":1685997172934,"user_tz":-330,"elapsed":17923,"user":{"displayName":"Philemon Daniel","userId":"06587091607560878110"}},"outputId":"618f9cb8-bcef-41c4-9756-4622d415c181"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n","16/16 [==============================] - 2s 2ms/step - loss: 2.4398 - reconstruction_loss: 0.7327 - kl_loss: 1.3863\n","Epoch 2/300\n","16/16 [==============================] - 0s 3ms/step - loss: 1.4173 - reconstruction_loss: 0.7237 - kl_loss: 0.6249\n","Epoch 3/300\n","16/16 [==============================] - 0s 2ms/step - loss: 1.1444 - reconstruction_loss: 0.7147 - kl_loss: 0.3966\n","Epoch 4/300\n","16/16 [==============================] - 0s 2ms/step - loss: 1.0294 - reconstruction_loss: 0.7197 - kl_loss: 0.2928\n","Epoch 5/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.9557 - reconstruction_loss: 0.7125 - kl_loss: 0.2286\n","Epoch 6/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.9061 - reconstruction_loss: 0.7123 - kl_loss: 0.1847\n","Epoch 7/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.8663 - reconstruction_loss: 0.7078 - kl_loss: 0.1530\n","Epoch 8/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.8390 - reconstruction_loss: 0.7080 - kl_loss: 0.1292\n","Epoch 9/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.8257 - reconstruction_loss: 0.7097 - kl_loss: 0.1106\n","Epoch 10/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.8011 - reconstruction_loss: 0.7024 - kl_loss: 0.0960\n","Epoch 11/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7949 - reconstruction_loss: 0.7054 - kl_loss: 0.0842\n","Epoch 12/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.7843 - reconstruction_loss: 0.7074 - kl_loss: 0.0746\n","Epoch 13/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7712 - reconstruction_loss: 0.7039 - kl_loss: 0.0666\n","Epoch 14/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.7649 - reconstruction_loss: 0.7040 - kl_loss: 0.0597\n","Epoch 15/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7587 - reconstruction_loss: 0.7038 - kl_loss: 0.0539\n","Epoch 16/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7498 - reconstruction_loss: 0.7013 - kl_loss: 0.0489\n","Epoch 17/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7464 - reconstruction_loss: 0.7009 - kl_loss: 0.0445\n","Epoch 18/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.7468 - reconstruction_loss: 0.7041 - kl_loss: 0.0408\n","Epoch 19/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7399 - reconstruction_loss: 0.7008 - kl_loss: 0.0374\n","Epoch 20/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7339 - reconstruction_loss: 0.6986 - kl_loss: 0.0344\n","Epoch 21/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7314 - reconstruction_loss: 0.7014 - kl_loss: 0.0317\n","Epoch 22/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7279 - reconstruction_loss: 0.6997 - kl_loss: 0.0293\n","Epoch 23/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7282 - reconstruction_loss: 0.7019 - kl_loss: 0.0271\n","Epoch 24/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7250 - reconstruction_loss: 0.7001 - kl_loss: 0.0251\n","Epoch 25/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7252 - reconstruction_loss: 0.7006 - kl_loss: 0.0233\n","Epoch 26/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7220 - reconstruction_loss: 0.7008 - kl_loss: 0.0217\n","Epoch 27/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7200 - reconstruction_loss: 0.6996 - kl_loss: 0.0202\n","Epoch 28/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.7196 - reconstruction_loss: 0.7002 - kl_loss: 0.0188\n","Epoch 29/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7175 - reconstruction_loss: 0.6984 - kl_loss: 0.0176\n","Epoch 30/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7173 - reconstruction_loss: 0.6999 - kl_loss: 0.0164\n","Epoch 31/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7162 - reconstruction_loss: 0.7003 - kl_loss: 0.0153\n","Epoch 32/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7105 - reconstruction_loss: 0.6976 - kl_loss: 0.0143\n","Epoch 33/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7113 - reconstruction_loss: 0.6989 - kl_loss: 0.0134\n","Epoch 34/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7101 - reconstruction_loss: 0.6988 - kl_loss: 0.0126\n","Epoch 35/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7088 - reconstruction_loss: 0.6971 - kl_loss: 0.0118\n","Epoch 36/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.7086 - reconstruction_loss: 0.6985 - kl_loss: 0.0111\n","Epoch 37/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7073 - reconstruction_loss: 0.6968 - kl_loss: 0.0104\n","Epoch 38/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7056 - reconstruction_loss: 0.6977 - kl_loss: 0.0098\n","Epoch 39/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.7070 - reconstruction_loss: 0.6965 - kl_loss: 0.0092\n","Epoch 40/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7067 - reconstruction_loss: 0.6984 - kl_loss: 0.0086\n","Epoch 41/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7065 - reconstruction_loss: 0.6981 - kl_loss: 0.0081\n","Epoch 42/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7020 - reconstruction_loss: 0.6958 - kl_loss: 0.0076\n","Epoch 43/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7041 - reconstruction_loss: 0.6961 - kl_loss: 0.0072\n","Epoch 44/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7023 - reconstruction_loss: 0.6955 - kl_loss: 0.0067\n","Epoch 45/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7055 - reconstruction_loss: 0.6992 - kl_loss: 0.0064\n","Epoch 46/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7047 - reconstruction_loss: 0.6985 - kl_loss: 0.0060\n","Epoch 47/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7021 - reconstruction_loss: 0.6969 - kl_loss: 0.0057\n","Epoch 48/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7012 - reconstruction_loss: 0.6950 - kl_loss: 0.0053\n","Epoch 49/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7005 - reconstruction_loss: 0.6952 - kl_loss: 0.0050\n","Epoch 50/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7010 - reconstruction_loss: 0.6962 - kl_loss: 0.0048\n","Epoch 51/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7006 - reconstruction_loss: 0.6959 - kl_loss: 0.0045\n","Epoch 52/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7004 - reconstruction_loss: 0.6961 - kl_loss: 0.0043\n","Epoch 53/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7005 - reconstruction_loss: 0.6967 - kl_loss: 0.0040\n","Epoch 54/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6999 - reconstruction_loss: 0.6966 - kl_loss: 0.0038\n","Epoch 55/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6994 - reconstruction_loss: 0.6966 - kl_loss: 0.0036\n","Epoch 56/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6988 - reconstruction_loss: 0.6949 - kl_loss: 0.0035\n","Epoch 57/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6984 - reconstruction_loss: 0.6957 - kl_loss: 0.0033\n","Epoch 58/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6979 - reconstruction_loss: 0.6956 - kl_loss: 0.0031\n","Epoch 59/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6973 - reconstruction_loss: 0.6936 - kl_loss: 0.0030\n","Epoch 60/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6968 - reconstruction_loss: 0.6956 - kl_loss: 0.0029\n","Epoch 61/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6991 - reconstruction_loss: 0.6965 - kl_loss: 0.0027\n","Epoch 62/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6978 - reconstruction_loss: 0.6956 - kl_loss: 0.0026\n","Epoch 63/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6998 - reconstruction_loss: 0.6968 - kl_loss: 0.0025\n","Epoch 64/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6978 - reconstruction_loss: 0.6953 - kl_loss: 0.0024\n","Epoch 65/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6988 - reconstruction_loss: 0.6969 - kl_loss: 0.0023\n","Epoch 66/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6968 - reconstruction_loss: 0.6950 - kl_loss: 0.0022\n","Epoch 67/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6972 - reconstruction_loss: 0.6956 - kl_loss: 0.0021\n","Epoch 68/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6996 - reconstruction_loss: 0.6962 - kl_loss: 0.0020\n","Epoch 69/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.7003 - reconstruction_loss: 0.6975 - kl_loss: 0.0019\n","Epoch 70/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6988 - reconstruction_loss: 0.6974 - kl_loss: 0.0018\n","Epoch 71/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6958 - reconstruction_loss: 0.6951 - kl_loss: 0.0018\n","Epoch 72/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6996 - reconstruction_loss: 0.6969 - kl_loss: 0.0017\n","Epoch 73/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6973 - reconstruction_loss: 0.6954 - kl_loss: 0.0016\n","Epoch 74/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6987 - reconstruction_loss: 0.6974 - kl_loss: 0.0016\n","Epoch 75/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6952 - reconstruction_loss: 0.6942 - kl_loss: 0.0015\n","Epoch 76/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6966 - reconstruction_loss: 0.6958 - kl_loss: 0.0014\n","Epoch 77/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6984 - reconstruction_loss: 0.6964 - kl_loss: 0.0014\n","Epoch 78/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6953 - reconstruction_loss: 0.6949 - kl_loss: 0.0013\n","Epoch 79/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6981 - reconstruction_loss: 0.6962 - kl_loss: 0.0013\n","Epoch 80/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6959 - reconstruction_loss: 0.6946 - kl_loss: 0.0012\n","Epoch 81/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6992 - reconstruction_loss: 0.6965 - kl_loss: 0.0012\n","Epoch 82/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6977 - reconstruction_loss: 0.6957 - kl_loss: 0.0011\n","Epoch 83/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6962 - reconstruction_loss: 0.6962 - kl_loss: 0.0011\n","Epoch 84/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6963 - reconstruction_loss: 0.6963 - kl_loss: 0.0011\n","Epoch 85/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6968 - reconstruction_loss: 0.6954 - kl_loss: 0.0010\n","Epoch 86/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6976 - reconstruction_loss: 0.6959 - kl_loss: 9.8168e-04\n","Epoch 87/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6991 - reconstruction_loss: 0.6980 - kl_loss: 9.4519e-04\n","Epoch 88/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6968 - reconstruction_loss: 0.6963 - kl_loss: 9.1535e-04\n","Epoch 89/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6969 - reconstruction_loss: 0.6954 - kl_loss: 8.8255e-04\n","Epoch 90/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6971 - reconstruction_loss: 0.6955 - kl_loss: 8.5304e-04\n","Epoch 91/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6965 - reconstruction_loss: 0.6950 - kl_loss: 8.2517e-04\n","Epoch 92/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6971 - reconstruction_loss: 0.6947 - kl_loss: 7.9242e-04\n","Epoch 93/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6964 - reconstruction_loss: 0.6961 - kl_loss: 7.6406e-04\n","Epoch 94/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6964 - reconstruction_loss: 0.6958 - kl_loss: 7.3830e-04\n","Epoch 95/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6957 - reconstruction_loss: 0.6951 - kl_loss: 7.1255e-04\n","Epoch 96/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6947 - reconstruction_loss: 0.6951 - kl_loss: 6.8762e-04\n","Epoch 97/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6965 - reconstruction_loss: 0.6964 - kl_loss: 6.6462e-04\n","Epoch 98/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6976 - reconstruction_loss: 0.6961 - kl_loss: 6.4363e-04\n","Epoch 99/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6946 - reconstruction_loss: 0.6939 - kl_loss: 6.2108e-04\n","Epoch 100/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6948 - reconstruction_loss: 0.6948 - kl_loss: 5.9924e-04\n","Epoch 101/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6973 - reconstruction_loss: 0.6956 - kl_loss: 5.7899e-04\n","Epoch 102/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6965 - reconstruction_loss: 0.6944 - kl_loss: 5.6131e-04\n","Epoch 103/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6950 - reconstruction_loss: 0.6948 - kl_loss: 5.4333e-04\n","Epoch 104/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6961 - reconstruction_loss: 0.6959 - kl_loss: 5.2510e-04\n","Epoch 105/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6946 - reconstruction_loss: 0.6950 - kl_loss: 5.0872e-04\n","Epoch 106/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6952 - reconstruction_loss: 0.6946 - kl_loss: 4.9219e-04\n","Epoch 107/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6969 - reconstruction_loss: 0.6958 - kl_loss: 4.7808e-04\n","Epoch 108/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6955 - reconstruction_loss: 0.6948 - kl_loss: 4.6104e-04\n","Epoch 109/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6955 - reconstruction_loss: 0.6951 - kl_loss: 4.4732e-04\n","Epoch 110/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6938 - reconstruction_loss: 0.6938 - kl_loss: 4.3417e-04\n","Epoch 111/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6953 - reconstruction_loss: 0.6944 - kl_loss: 4.2050e-04\n","Epoch 112/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6943 - reconstruction_loss: 0.6945 - kl_loss: 4.0712e-04\n","Epoch 113/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6957 - reconstruction_loss: 0.6950 - kl_loss: 3.9638e-04\n","Epoch 114/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6967 - reconstruction_loss: 0.6960 - kl_loss: 3.8477e-04\n","Epoch 115/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6961 - reconstruction_loss: 0.6954 - kl_loss: 3.7408e-04\n","Epoch 116/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6967 - reconstruction_loss: 0.6959 - kl_loss: 3.6261e-04\n","Epoch 117/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6939 - reconstruction_loss: 0.6940 - kl_loss: 3.5135e-04\n","Epoch 118/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6947 - reconstruction_loss: 0.6949 - kl_loss: 3.4103e-04\n","Epoch 119/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6967 - reconstruction_loss: 0.6962 - kl_loss: 3.3143e-04\n","Epoch 120/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6929 - reconstruction_loss: 0.6941 - kl_loss: 3.2157e-04\n","Epoch 121/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - reconstruction_loss: 0.6935 - kl_loss: 3.1221e-04\n","Epoch 122/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6963 - reconstruction_loss: 0.6959 - kl_loss: 3.0490e-04\n","Epoch 123/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6954 - reconstruction_loss: 0.6950 - kl_loss: 2.9629e-04\n","Epoch 124/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6953 - reconstruction_loss: 0.6949 - kl_loss: 2.8747e-04\n","Epoch 125/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6942 - reconstruction_loss: 0.6946 - kl_loss: 2.7830e-04\n","Epoch 126/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6949 - reconstruction_loss: 0.6944 - kl_loss: 2.7183e-04\n","Epoch 127/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6944 - reconstruction_loss: 0.6941 - kl_loss: 2.6329e-04\n","Epoch 128/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6962 - reconstruction_loss: 0.6957 - kl_loss: 2.5549e-04\n","Epoch 129/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6951 - reconstruction_loss: 0.6953 - kl_loss: 2.4934e-04\n","Epoch 130/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6945 - reconstruction_loss: 0.6946 - kl_loss: 2.4266e-04\n","Epoch 131/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6954 - reconstruction_loss: 0.6954 - kl_loss: 2.3582e-04\n","Epoch 132/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6942 - reconstruction_loss: 0.6937 - kl_loss: 2.2989e-04\n","Epoch 133/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6953 - reconstruction_loss: 0.6947 - kl_loss: 2.2401e-04\n","Epoch 134/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6947 - reconstruction_loss: 0.6950 - kl_loss: 2.1748e-04\n","Epoch 135/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6956 - reconstruction_loss: 0.6954 - kl_loss: 2.1193e-04\n","Epoch 136/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6962 - reconstruction_loss: 0.6955 - kl_loss: 2.0606e-04\n","Epoch 137/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6948 - reconstruction_loss: 0.6944 - kl_loss: 2.0033e-04\n","Epoch 138/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6956 - reconstruction_loss: 0.6954 - kl_loss: 1.9578e-04\n","Epoch 139/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6946 - reconstruction_loss: 0.6947 - kl_loss: 1.9008e-04\n","Epoch 140/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6953 - reconstruction_loss: 0.6946 - kl_loss: 1.8532e-04\n","Epoch 141/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6951 - reconstruction_loss: 0.6945 - kl_loss: 1.8069e-04\n","Epoch 142/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6952 - reconstruction_loss: 0.6948 - kl_loss: 1.7577e-04\n","Epoch 143/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6947 - reconstruction_loss: 0.6943 - kl_loss: 1.7165e-04\n","Epoch 144/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6942 - reconstruction_loss: 0.6940 - kl_loss: 1.6723e-04\n","Epoch 145/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6959 - reconstruction_loss: 0.6958 - kl_loss: 1.6257e-04\n","Epoch 146/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6939 - reconstruction_loss: 0.6934 - kl_loss: 1.5893e-04\n","Epoch 147/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6941 - reconstruction_loss: 0.6944 - kl_loss: 1.5544e-04\n","Epoch 148/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6957 - reconstruction_loss: 0.6945 - kl_loss: 1.5209e-04\n","Epoch 149/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6937 - reconstruction_loss: 0.6943 - kl_loss: 1.4789e-04\n","Epoch 150/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6944 - reconstruction_loss: 0.6951 - kl_loss: 1.4391e-04\n","Epoch 151/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6951 - reconstruction_loss: 0.6943 - kl_loss: 1.4064e-04\n","Epoch 152/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6935 - reconstruction_loss: 0.6938 - kl_loss: 1.3748e-04\n","Epoch 153/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6952 - reconstruction_loss: 0.6953 - kl_loss: 1.3567e-04\n","Epoch 154/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6953 - reconstruction_loss: 0.6951 - kl_loss: 1.3291e-04\n","Epoch 155/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6931 - reconstruction_loss: 0.6935 - kl_loss: 1.2997e-04\n","Epoch 156/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6938 - reconstruction_loss: 0.6949 - kl_loss: 1.2817e-04\n","Epoch 157/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6948 - reconstruction_loss: 0.6944 - kl_loss: 1.2528e-04\n","Epoch 158/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6954 - reconstruction_loss: 0.6946 - kl_loss: 1.2196e-04\n","Epoch 159/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6945 - reconstruction_loss: 0.6950 - kl_loss: 1.2025e-04\n","Epoch 160/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6949 - reconstruction_loss: 0.6940 - kl_loss: 1.1754e-04\n","Epoch 161/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6941 - reconstruction_loss: 0.6941 - kl_loss: 1.1565e-04\n","Epoch 162/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6950 - reconstruction_loss: 0.6943 - kl_loss: 1.1210e-04\n","Epoch 163/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6960 - reconstruction_loss: 0.6957 - kl_loss: 1.1005e-04\n","Epoch 164/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6933 - reconstruction_loss: 0.6933 - kl_loss: 1.0838e-04\n","Epoch 165/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6945 - reconstruction_loss: 0.6947 - kl_loss: 1.0636e-04\n","Epoch 166/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6945 - reconstruction_loss: 0.6940 - kl_loss: 1.0495e-04\n","Epoch 167/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6934 - reconstruction_loss: 0.6937 - kl_loss: 1.0386e-04\n","Epoch 168/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6953 - reconstruction_loss: 0.6946 - kl_loss: 1.0047e-04\n","Epoch 169/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6941 - reconstruction_loss: 0.6943 - kl_loss: 9.9242e-05\n","Epoch 170/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6944 - reconstruction_loss: 0.6951 - kl_loss: 9.7966e-05\n","Epoch 171/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6956 - reconstruction_loss: 0.6951 - kl_loss: 9.6029e-05\n","Epoch 172/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6928 - reconstruction_loss: 0.6933 - kl_loss: 9.4196e-05\n","Epoch 173/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6940 - reconstruction_loss: 0.6941 - kl_loss: 9.2681e-05\n","Epoch 174/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6946 - reconstruction_loss: 0.6944 - kl_loss: 9.1092e-05\n","Epoch 175/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6936 - reconstruction_loss: 0.6941 - kl_loss: 8.9399e-05\n","Epoch 176/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6939 - reconstruction_loss: 0.6939 - kl_loss: 8.7728e-05\n","Epoch 177/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6955 - reconstruction_loss: 0.6947 - kl_loss: 8.7158e-05\n","Epoch 178/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6936 - reconstruction_loss: 0.6941 - kl_loss: 8.7215e-05\n","Epoch 179/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6933 - reconstruction_loss: 0.6937 - kl_loss: 8.4551e-05\n","Epoch 180/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6947 - reconstruction_loss: 0.6946 - kl_loss: 8.1192e-05\n","Epoch 181/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6958 - reconstruction_loss: 0.6947 - kl_loss: 7.9829e-05\n","Epoch 182/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6942 - reconstruction_loss: 0.6946 - kl_loss: 7.8077e-05\n","Epoch 183/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6939 - reconstruction_loss: 0.6937 - kl_loss: 7.7738e-05\n","Epoch 184/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6940 - reconstruction_loss: 0.6946 - kl_loss: 7.5643e-05\n","Epoch 185/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6947 - reconstruction_loss: 0.6942 - kl_loss: 7.4749e-05\n","Epoch 186/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6944 - reconstruction_loss: 0.6947 - kl_loss: 7.3206e-05\n","Epoch 187/300\n","16/16 [==============================] - 0s 5ms/step - loss: 0.6946 - reconstruction_loss: 0.6945 - kl_loss: 7.0778e-05\n","Epoch 188/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6938 - reconstruction_loss: 0.6941 - kl_loss: 6.9625e-05\n","Epoch 189/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6954 - reconstruction_loss: 0.6948 - kl_loss: 6.8352e-05\n","Epoch 190/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6948 - reconstruction_loss: 0.6948 - kl_loss: 6.6211e-05\n","Epoch 191/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6942 - reconstruction_loss: 0.6938 - kl_loss: 6.5030e-05\n","Epoch 192/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6936 - reconstruction_loss: 0.6935 - kl_loss: 6.3988e-05\n","Epoch 193/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - reconstruction_loss: 0.6935 - kl_loss: 6.3361e-05\n","Epoch 194/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6947 - reconstruction_loss: 0.6942 - kl_loss: 6.2751e-05\n","Epoch 195/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6940 - reconstruction_loss: 0.6944 - kl_loss: 6.2373e-05\n","Epoch 196/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6942 - reconstruction_loss: 0.6938 - kl_loss: 6.0569e-05\n","Epoch 197/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6951 - reconstruction_loss: 0.6941 - kl_loss: 5.9399e-05\n","Epoch 198/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6936 - reconstruction_loss: 0.6935 - kl_loss: 5.8201e-05\n","Epoch 199/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6943 - reconstruction_loss: 0.6943 - kl_loss: 5.7553e-05\n","Epoch 200/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6948 - reconstruction_loss: 0.6944 - kl_loss: 5.6581e-05\n","Epoch 201/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6953 - reconstruction_loss: 0.6943 - kl_loss: 5.5936e-05\n","Epoch 202/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6931 - reconstruction_loss: 0.6932 - kl_loss: 5.4711e-05\n","Epoch 203/300\n","16/16 [==============================] - 0s 5ms/step - loss: 0.6943 - reconstruction_loss: 0.6949 - kl_loss: 5.3594e-05\n","Epoch 204/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6954 - reconstruction_loss: 0.6942 - kl_loss: 5.3064e-05\n","Epoch 205/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6939 - reconstruction_loss: 0.6939 - kl_loss: 5.2411e-05\n","Epoch 206/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6943 - reconstruction_loss: 0.6944 - kl_loss: 5.1360e-05\n","Epoch 207/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6934 - reconstruction_loss: 0.6939 - kl_loss: 5.0669e-05\n","Epoch 208/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6936 - reconstruction_loss: 0.6939 - kl_loss: 4.9977e-05\n","Epoch 209/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6934 - reconstruction_loss: 0.6939 - kl_loss: 4.9469e-05\n","Epoch 210/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6929 - reconstruction_loss: 0.6934 - kl_loss: 4.9580e-05\n","Epoch 211/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6940 - reconstruction_loss: 0.6942 - kl_loss: 4.8450e-05\n","Epoch 212/300\n","16/16 [==============================] - 0s 5ms/step - loss: 0.6938 - reconstruction_loss: 0.6942 - kl_loss: 4.7219e-05\n","Epoch 213/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - reconstruction_loss: 0.6936 - kl_loss: 4.6498e-05\n","Epoch 214/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6941 - reconstruction_loss: 0.6940 - kl_loss: 4.5976e-05\n","Epoch 215/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6933 - reconstruction_loss: 0.6937 - kl_loss: 4.4997e-05\n","Epoch 216/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6942 - reconstruction_loss: 0.6936 - kl_loss: 4.4334e-05\n","Epoch 217/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6939 - reconstruction_loss: 0.6949 - kl_loss: 4.4084e-05\n","Epoch 218/300\n","16/16 [==============================] - 0s 5ms/step - loss: 0.6954 - reconstruction_loss: 0.6951 - kl_loss: 4.3806e-05\n","Epoch 219/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6937 - reconstruction_loss: 0.6940 - kl_loss: 4.3782e-05\n","Epoch 220/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6940 - reconstruction_loss: 0.6939 - kl_loss: 4.2611e-05\n","Epoch 221/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6943 - reconstruction_loss: 0.6942 - kl_loss: 4.2158e-05\n","Epoch 222/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6944 - reconstruction_loss: 0.6937 - kl_loss: 4.1778e-05\n","Epoch 223/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6944 - reconstruction_loss: 0.6942 - kl_loss: 4.0718e-05\n","Epoch 224/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6940 - reconstruction_loss: 0.6942 - kl_loss: 3.9951e-05\n","Epoch 225/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6928 - reconstruction_loss: 0.6934 - kl_loss: 3.9659e-05\n","Epoch 226/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6945 - reconstruction_loss: 0.6941 - kl_loss: 3.9106e-05\n","Epoch 227/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6938 - reconstruction_loss: 0.6947 - kl_loss: 3.9514e-05\n","Epoch 228/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6935 - reconstruction_loss: 0.6937 - kl_loss: 3.9511e-05\n","Epoch 229/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6935 - reconstruction_loss: 0.6941 - kl_loss: 3.8302e-05\n","Epoch 230/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6939 - reconstruction_loss: 0.6935 - kl_loss: 3.7560e-05\n","Epoch 231/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - reconstruction_loss: 0.6934 - kl_loss: 3.6243e-05\n","Epoch 232/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - reconstruction_loss: 0.6933 - kl_loss: 3.5854e-05\n","Epoch 233/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6943 - reconstruction_loss: 0.6936 - kl_loss: 3.5362e-05\n","Epoch 234/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6936 - reconstruction_loss: 0.6937 - kl_loss: 3.4911e-05\n","Epoch 235/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6946 - reconstruction_loss: 0.6939 - kl_loss: 3.4560e-05\n","Epoch 236/300\n","16/16 [==============================] - 0s 5ms/step - loss: 0.6937 - reconstruction_loss: 0.6937 - kl_loss: 3.4026e-05\n","Epoch 237/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6942 - reconstruction_loss: 0.6941 - kl_loss: 3.3364e-05\n","Epoch 238/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6940 - reconstruction_loss: 0.6939 - kl_loss: 3.3452e-05\n","Epoch 239/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6936 - reconstruction_loss: 0.6936 - kl_loss: 3.3265e-05\n","Epoch 240/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6943 - reconstruction_loss: 0.6940 - kl_loss: 3.1924e-05\n","Epoch 241/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6941 - reconstruction_loss: 0.6938 - kl_loss: 3.1985e-05\n","Epoch 242/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6947 - reconstruction_loss: 0.6945 - kl_loss: 3.1033e-05\n","Epoch 243/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6942 - reconstruction_loss: 0.6941 - kl_loss: 3.0440e-05\n","Epoch 244/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6932 - reconstruction_loss: 0.6939 - kl_loss: 2.9837e-05\n","Epoch 245/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6939 - reconstruction_loss: 0.6942 - kl_loss: 2.9778e-05\n","Epoch 246/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6938 - reconstruction_loss: 0.6937 - kl_loss: 2.9400e-05\n","Epoch 247/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6939 - reconstruction_loss: 0.6943 - kl_loss: 2.8939e-05\n","Epoch 248/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6960 - reconstruction_loss: 0.6951 - kl_loss: 2.8961e-05\n","Epoch 249/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6943 - reconstruction_loss: 0.6940 - kl_loss: 2.8505e-05\n","Epoch 250/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6937 - reconstruction_loss: 0.6938 - kl_loss: 2.6999e-05\n","Epoch 251/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6940 - reconstruction_loss: 0.6939 - kl_loss: 2.6944e-05\n","Epoch 252/300\n","16/16 [==============================] - 0s 4ms/step - loss: 0.6940 - reconstruction_loss: 0.6937 - kl_loss: 2.6366e-05\n","Epoch 253/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6938 - reconstruction_loss: 0.6938 - kl_loss: 2.5408e-05\n","Epoch 254/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6945 - reconstruction_loss: 0.6949 - kl_loss: 2.5685e-05\n","Epoch 255/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6945 - reconstruction_loss: 0.6948 - kl_loss: 2.5516e-05\n","Epoch 256/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6943 - reconstruction_loss: 0.6939 - kl_loss: 2.4634e-05\n","Epoch 257/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6932 - reconstruction_loss: 0.6933 - kl_loss: 2.4056e-05\n","Epoch 258/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6944 - reconstruction_loss: 0.6943 - kl_loss: 2.4081e-05\n","Epoch 259/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6938 - reconstruction_loss: 0.6939 - kl_loss: 2.3204e-05\n","Epoch 260/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6940 - reconstruction_loss: 0.6942 - kl_loss: 2.3240e-05\n","Epoch 261/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6937 - reconstruction_loss: 0.6935 - kl_loss: 2.2864e-05\n","Epoch 262/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6946 - reconstruction_loss: 0.6936 - kl_loss: 2.2489e-05\n","Epoch 263/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6938 - reconstruction_loss: 0.6940 - kl_loss: 2.2470e-05\n","Epoch 264/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6925 - reconstruction_loss: 0.6930 - kl_loss: 2.2379e-05\n","Epoch 265/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6933 - reconstruction_loss: 0.6937 - kl_loss: 2.2479e-05\n","Epoch 266/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6939 - reconstruction_loss: 0.6939 - kl_loss: 2.1614e-05\n","Epoch 267/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - reconstruction_loss: 0.6938 - kl_loss: 2.2027e-05\n","Epoch 268/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6942 - reconstruction_loss: 0.6944 - kl_loss: 2.1854e-05\n","Epoch 269/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6940 - reconstruction_loss: 0.6938 - kl_loss: 2.1462e-05\n","Epoch 270/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6938 - reconstruction_loss: 0.6943 - kl_loss: 2.2221e-05\n","Epoch 271/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6946 - reconstruction_loss: 0.6946 - kl_loss: 2.1968e-05\n","Epoch 272/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6936 - reconstruction_loss: 0.6942 - kl_loss: 2.0743e-05\n","Epoch 273/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6932 - reconstruction_loss: 0.6936 - kl_loss: 2.0188e-05\n","Epoch 274/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6942 - reconstruction_loss: 0.6942 - kl_loss: 2.0183e-05\n","Epoch 275/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6939 - reconstruction_loss: 0.6938 - kl_loss: 2.0230e-05\n","Epoch 276/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6941 - reconstruction_loss: 0.6937 - kl_loss: 1.9024e-05\n","Epoch 277/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6934 - reconstruction_loss: 0.6938 - kl_loss: 1.8648e-05\n","Epoch 278/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6943 - reconstruction_loss: 0.6938 - kl_loss: 1.8259e-05\n","Epoch 279/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6934 - reconstruction_loss: 0.6935 - kl_loss: 1.8157e-05\n","Epoch 280/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6940 - reconstruction_loss: 0.6945 - kl_loss: 1.8162e-05\n","Epoch 281/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6935 - reconstruction_loss: 0.6932 - kl_loss: 1.7844e-05\n","Epoch 282/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6937 - reconstruction_loss: 0.6940 - kl_loss: 1.7779e-05\n","Epoch 283/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6940 - reconstruction_loss: 0.6938 - kl_loss: 1.8069e-05\n","Epoch 284/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6939 - reconstruction_loss: 0.6942 - kl_loss: 1.7772e-05\n","Epoch 285/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6931 - reconstruction_loss: 0.6935 - kl_loss: 1.7388e-05\n","Epoch 286/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6934 - reconstruction_loss: 0.6936 - kl_loss: 1.7013e-05\n","Epoch 287/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6947 - reconstruction_loss: 0.6941 - kl_loss: 1.6573e-05\n","Epoch 288/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6939 - reconstruction_loss: 0.6935 - kl_loss: 1.6611e-05\n","Epoch 289/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6934 - reconstruction_loss: 0.6936 - kl_loss: 1.7114e-05\n","Epoch 290/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6942 - reconstruction_loss: 0.6940 - kl_loss: 1.6360e-05\n","Epoch 291/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6934 - reconstruction_loss: 0.6939 - kl_loss: 1.6505e-05\n","Epoch 292/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6944 - reconstruction_loss: 0.6945 - kl_loss: 1.6051e-05\n","Epoch 293/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6934 - reconstruction_loss: 0.6939 - kl_loss: 1.5917e-05\n","Epoch 294/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6947 - reconstruction_loss: 0.6946 - kl_loss: 1.5393e-05\n","Epoch 295/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6934 - reconstruction_loss: 0.6936 - kl_loss: 1.5219e-05\n","Epoch 296/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6939 - reconstruction_loss: 0.6937 - kl_loss: 1.5590e-05\n","Epoch 297/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6934 - reconstruction_loss: 0.6938 - kl_loss: 1.5346e-05\n","Epoch 298/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6940 - reconstruction_loss: 0.6938 - kl_loss: 1.5642e-05\n","Epoch 299/300\n","16/16 [==============================] - 0s 3ms/step - loss: 0.6920 - reconstruction_loss: 0.6927 - kl_loss: 1.5540e-05\n","Epoch 300/300\n","16/16 [==============================] - 0s 2ms/step - loss: 0.6940 - reconstruction_loss: 0.6940 - kl_loss: 1.4914e-05\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0875f8d450>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["def generate_test_vectors(vae, num_samples):\n","    # Sample random points in the latent space\n","    random_latent_vectors = tf.random.normal(shape=(num_samples, latent_dim))\n","    \n","    # Decode them to fake data (test vectors)\n","    generated_data = vae.decoder.predict(random_latent_vectors)\n","    \n","    # Binarize the data\n","    generated_data = np.where(generated_data > 0.5, 1, 0)\n","\n","    return generated_data\n","\n","# Generate some test vectors\n","num_samples = 10  # define how many samples you want to generate\n","generated_data = generate_test_vectors(vae, num_samples)\n","\n","# Print the generated test vectors\n","print(generated_data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WLtKFjCLPLDp","executionInfo":{"status":"ok","timestamp":1685997353797,"user_tz":-330,"elapsed":459,"user":{"displayName":"Philemon Daniel","userId":"06587091607560878110"}},"outputId":"4a925e8e-a3de-4b33-c898-ea42a8f6b08e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 145ms/step\n","[[0 0 0 1 0 0 0 0 0 0 0 1 1 1]\n"," [0 1 0 0 0 1 0 0 1 1 1 1 1 1]\n"," [1 1 1 1 1 0 0 0 0 0 0 0 0 1]\n"," [0 1 1 1 1 0 1 0 0 1 0 1 0 1]\n"," [0 1 0 1 0 1 0 0 0 1 0 0 0 0]\n"," [1 0 1 0 1 1 1 1 0 1 1 0 0 1]\n"," [1 1 1 0 1 0 1 1 1 1 0 1 1 1]\n"," [1 1 1 0 1 0 1 1 0 0 0 0 1 1]\n"," [0 1 0 0 0 1 1 0 0 0 1 0 1 0]\n"," [0 0 0 1 1 1 1 0 1 0 0 1 0 1]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GjpqRoNpRfS9"},"execution_count":null,"outputs":[]}]}